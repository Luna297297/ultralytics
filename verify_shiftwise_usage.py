"""é©—è­‰ ShiftWise æ˜¯å¦çœŸçš„åœ¨ä½¿ç”¨ï¼Œè€Œä¸æ˜¯ fallback åˆ°æ¨™æº–å·ç©

é€™å€‹è…³æœ¬æœƒè©³ç´°æª¢æŸ¥ï¼š
1. ShiftWise æ¨¡çµ„æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
2. æ˜¯å¦çœŸçš„ä½¿ç”¨ ShiftWise CUDA è·¯å¾‘
3. å¦‚ä½•å€åˆ† ShiftWise å’Œ fallback
"""

import torch
from ultralytics import YOLO


def verify_shiftwise_usage():
    """è©³ç´°é©—è­‰ ShiftWise çš„ä½¿ç”¨æƒ…æ³"""
    print("=" * 70)
    print("ShiftWise ä½¿ç”¨æƒ…æ³é©—è­‰")
    print("=" * 70)
    
    # è¼‰å…¥æ¨¡å‹
    print("\n1. è¼‰å…¥æ¨¡å‹...")
    try:
        model = YOLO("/content/ultralytics/ultralytics/cfg/models/12/yolo12s_shiftwise.yaml")
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # ç§»åˆ° CUDA
    if torch.cuda.is_available():
        model.model.to("cuda")
        print("âœ… æ¨¡å‹å·²ç§»åˆ° CUDA")
    else:
        print("âš ï¸  CUDA ä¸å¯ç”¨ï¼ŒShiftWise å°‡ä½¿ç”¨ fallback")
    
    # æª¢æŸ¥æ‰€æœ‰ ShiftWiseConv
    print("\n" + "=" * 70)
    print("2. æª¢æŸ¥ ShiftWiseConv æ¨¡çµ„ç‹€æ…‹")
    print("=" * 70)
    
    shiftwise_modules = []
    for name, module in model.model.named_modules():
        if module.__class__.__name__ == "ShiftWiseConv":
            shiftwise_modules.append((name, module))
    
    if not shiftwise_modules:
        print("âŒ æ²’æœ‰æ‰¾åˆ° ShiftWiseConv æ¨¡çµ„")
        return
    
    print(f"æ‰¾åˆ° {len(shiftwise_modules)} å€‹ ShiftWiseConv æ¨¡çµ„\n")
    
    for idx, (name, module) in enumerate(shiftwise_modules, 1):
        print(f"ğŸ“ [{idx}] {name}:")
        print(f"   big_k (ç­‰æ•ˆå¤§ kernel): {module.fallback_conv.kernel_size[0]}")
        print(f"   use_shiftwise: {module.use_shiftwise}")
        print(f"   has_shift_module: {module.shift is not None}")
        print(f"   has_channel_expand: {module.channel_expand is not None if hasattr(module, 'channel_expand') else False}")
        
        if hasattr(module, '_shift_module_class') and module._shift_module_class is not None:
            print(f"   shift_module_class: {module._shift_module_class.__name__}")
            print(f"   âš ï¸  å°šæœªåˆå§‹åŒ–ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰")
        elif module.shift is not None:
            print(f"   âœ… ShiftWise æ¨¡çµ„å·²åˆå§‹åŒ–")
            print(f"      - c_out: {module.shift.c_out}")
            print(f"      - c_in: {module.shift.c_in}")
            print(f"      - nk: {module.nk}")
        else:
            print(f"   âŒ ShiftWise æ¨¡çµ„æœªåˆå§‹åŒ–")
        
        print()
    
    # åŸ·è¡Œä¸€æ¬¡ forward ä¾†è§¸ç™¼åˆå§‹åŒ–
    print("=" * 70)
    print("3. åŸ·è¡Œ Forward Pass è§¸ç™¼åˆå§‹åŒ–")
    print("=" * 70)
    
    test_input = torch.randn(1, 3, 640, 640)
    if torch.cuda.is_available():
        test_input = test_input.cuda()
    
    print(f"æ¸¬è©¦è¼¸å…¥: {test_input.shape}, device: {test_input.device}")
    
    try:
        with torch.no_grad():
            output = model.model(test_input)
        print("âœ… Forward pass æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Forward pass å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # å†æ¬¡æª¢æŸ¥ç‹€æ…‹ï¼ˆåˆå§‹åŒ–å¾Œï¼‰
    print("\n" + "=" * 70)
    print("4. æª¢æŸ¥åˆå§‹åŒ–å¾Œçš„ç‹€æ…‹ï¼ˆForward å¾Œï¼‰")
    print("=" * 70)
    
    using_shiftwise_count = 0
    fallback_count = 0
    
    for idx, (name, module) in enumerate(shiftwise_modules, 1):
        print(f"\n[{idx}] {name}:")
        
        # æª¢æŸ¥æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        if module.shift is not None:
            print(f"   âœ… ShiftWise æ¨¡çµ„å·²åˆå§‹åŒ–")
            print(f"      - c_out: {module.shift.c_out}")
            print(f"      - c_in: {module.shift.c_in}")
            print(f"      - nk: {module.nk}")
        else:
            print(f"   âŒ ShiftWise æ¨¡çµ„æœªåˆå§‹åŒ–")
        
        # æª¢æŸ¥å¯¦éš›ä½¿ç”¨çš„è·¯å¾‘ï¼ˆé€šé _path_used æ¨™è¨˜ï¼‰
        path_used = getattr(module, '_path_used', None)
        if path_used == 'shiftwise':
            print(f"   âœ…âœ…âœ… å¯¦éš›ä½¿ç”¨ ShiftWise CUDA è·¯å¾‘ï¼")
            print(f"      â†’ ä½¿ç”¨ 3x3 small kernels + shift pattern")
            print(f"      â†’ å¯¦ç¾ç­‰æ•ˆ {module.fallback_conv.kernel_size[0]}x{module.fallback_conv.kernel_size[0]} big kernel")
            print(f"      â†’ å®Œå…¨ç¬¦åˆè«–æ–‡è¨­è¨ˆï¼")
            using_shiftwise_count += 1
        elif path_used == 'fallback':
            print(f"   âš ï¸  âš ï¸  âš ï¸  å¯¦éš›ä½¿ç”¨ Fallback è·¯å¾‘")
            print(f"      â†’ ç›´æ¥ä½¿ç”¨ {module.fallback_conv.kernel_size[0]}x{module.fallback_conv.kernel_size[0]} æ¨™æº–å·ç©")
            print(f"      â†’ æ²’æœ‰ä½¿ç”¨ ShiftWise çš„ shift pattern æ©Ÿåˆ¶")
            
            # æª¢æŸ¥ fallback çš„åŸå› 
            reasons = []
            if not module.use_shiftwise:
                reasons.append("use_shiftwise=False")
            if module.shift is None:
                reasons.append("shift=None (åˆå§‹åŒ–å¤±æ•—)")
            if not hasattr(module, 'channel_expand') or module.channel_expand is None:
                reasons.append("channel_expand=None")
            if module.stride != 1:
                reasons.append(f"stride={module.stride} != 1")
            if not test_input.is_cuda:
                reasons.append("è¼¸å…¥ä¸åœ¨ CUDA ä¸Š")
            
            if reasons:
                print(f"      åŸå› : {', '.join(reasons)}")
            
            fallback_count += 1
        else:
            print(f"   âš ï¸  å°šæœªåŸ·è¡Œ forwardï¼Œç„¡æ³•ç¢ºå®šä½¿ç”¨çš„è·¯å¾‘")
            print(f"      è«‹åŸ·è¡Œä¸€æ¬¡ forward pass ä¾†è§¸ç™¼åˆå§‹åŒ–")
    
    # ç¸½çµ
    print("\n" + "=" * 70)
    print("5. ç¸½çµ")
    print("=" * 70)
    
    print(f"\nğŸ“Š çµ±è¨ˆ:")
    print(f"   ä½¿ç”¨ ShiftWise CUDA è·¯å¾‘: {using_shiftwise_count} å€‹æ¨¡çµ„")
    print(f"   ä½¿ç”¨ Fallback è·¯å¾‘: {fallback_count} å€‹æ¨¡çµ„")
    
    if using_shiftwise_count > 0:
        print(f"\nâœ… æˆåŠŸï¼")
        print(f"   æœ‰ {using_shiftwise_count} å€‹ ShiftWiseConv ä½¿ç”¨ ShiftWise CUDA è·¯å¾‘")
        print(f"   é€™äº›æ¨¡çµ„ä½¿ç”¨ 3x3 small kernels + shift pattern")
        print(f"   ä¾†å¯¦ç¾ç­‰æ•ˆ big_k x big_k çš„å¤§ receptive field")
        print(f"   âœ… å®Œå…¨ç¬¦åˆè«–æ–‡è¨­è¨ˆï¼")
    else:
        print(f"\nâš ï¸  è­¦å‘Šï¼š")
        print(f"   æ‰€æœ‰ ShiftWiseConv éƒ½ä½¿ç”¨ fallback è·¯å¾‘")
        print(f"   é€™è¡¨ç¤º ShiftWise CUDA æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—æˆ–ä¸å¯ç”¨")
        print(f"   è«‹æª¢æŸ¥ï¼š")
        print(f"   1. shift-wiseConv æ˜¯å¦æ­£ç¢ºç·¨è­¯")
        print(f"   2. CUDA æ˜¯å¦å¯ç”¨")
        print(f"   3. PyTorch å’Œ CUDA ç‰ˆæœ¬æ˜¯å¦ç›¸å®¹")
    
    # æä¾›é©—è­‰æ–¹æ³•
    print("\n" + "=" * 70)
    print("6. å¦‚ä½•é©—è­‰å¯¦éš›é‹è¡Œæ™‚ä½¿ç”¨çš„è·¯å¾‘")
    print("=" * 70)
    
    print("""
æ–¹æ³• 1: æª¢æŸ¥æ¨¡çµ„ç‹€æ…‹ï¼ˆå·²åŸ·è¡Œï¼‰
  - å¦‚æœ shift is not None ä¸” use_shiftwise=Trueï¼Œæœƒä½¿ç”¨ ShiftWise è·¯å¾‘

æ–¹æ³• 2: ç›£æ§ forward èª¿ç”¨
  - å¯ä»¥åœ¨ ShiftWiseConv.forward ä¸­æ·»åŠ  print èªå¥
  - æŸ¥çœ‹æ˜¯å¦é€²å…¥ ShiftWise CUDA è·¯å¾‘

æ–¹æ³• 3: æ¯”è¼ƒè¨ˆç®—çµæœ
  - ShiftWise è·¯å¾‘å’Œ fallback è·¯å¾‘çš„è¼¸å‡ºæ‡‰è©²ä¸åŒ
  - å¯ä»¥ä¿å­˜å…©ç¨®è·¯å¾‘çš„è¼¸å‡ºé€²è¡Œæ¯”è¼ƒ

æ–¹æ³• 4: æª¢æŸ¥ CUDA kernel èª¿ç”¨
  - ä½¿ç”¨ nvidia-smi æˆ– CUDA profiler
  - æŸ¥çœ‹æ˜¯å¦æœ‰ ShiftWise CUDA kernel çš„èª¿ç”¨
    """)
    
    print("=" * 70)


if __name__ == "__main__":
    verify_shiftwise_usage()

